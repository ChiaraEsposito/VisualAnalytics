# -*- coding: utf-8 -*-
"""PCA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kAZjXtygci_M0hTgEZNOT7GdmD7e8Qfl
"""
#pip install seaborn

# Commented out IPython magic to ensure Python compatibility.
# Import standard libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

def pca():
    # Load the data from the csv file into a Pandas Dataframe
    original_data = pd.read_csv('./static/datasets/heart.csv')
    original_data.head()

    original_data.drop('FastingBS',axis=1,inplace=True)
    original_data.drop('ExerciseAngina',axis=1,inplace=True)
    original_data.drop('Oldpeak',axis=1,inplace=True)

    original_data.head()

    original_data.describe()

    original_data.corr()

    #PCA can only work with quantitative data, so we will replace:
    #Sex with [0,1] for [Male,Female];
    original_data.replace(to_replace="M",
                      value="0",
                      inplace=True)
    original_data.replace(to_replace="F",
                      value="1",
                      inplace=True)
    #Chest Pain with [0,1,2,3] for [ASY, TA, ATA, NAP];

    original_data.replace(to_replace="ASY",
                      value="0",
                      inplace=True)
    original_data.replace(to_replace="TA",
                      value="1",
                      inplace=True)
    original_data.replace(to_replace="ATA",
                      value="2",
                      inplace=True)
    original_data.replace(to_replace="NAP",
                      value="3",
                      inplace=True)
    #Resting ECG with [0,1,2] for [Normal, ST, LVH;
    original_data.replace(to_replace="Normal",
                      value="0",
                      inplace=True)
    original_data.replace(to_replace="ST",
                      value="1",
                      inplace=True)
    original_data.replace(to_replace="LVH",
                      value="2",
                      inplace=True)
    #ST_slope with [0,1,2] for [Down, Flat, Up].
    original_data.replace(to_replace="Down",
                      value="0",
                      inplace=True)
    original_data.replace(to_replace="Flat",
                      value="1",
                      inplace=True)
    original_data.replace(to_replace="Up",
                      value="2",
                      inplace=True)
    original_data.to_csv('./static/datasets/heart_quantitative.csv',
                     index=False)                  
    reduced_data = pd.read_csv('./static/datasets/heart.csv')
    reduced_data.drop(reduced_data[reduced_data['HeartDisease'] == 0].index, inplace = True)    
    reduced_data.to_csv('./static/datasets/heart_reduced.csv',
                     index=False)

    original_data['Age'] = original_data['Age'].mask(original_data['Age'] > 75 , 4)
    original_data['Age'] = original_data['Age'].mask(original_data['Age'] > 60 , 3)
    original_data['Age'] = original_data['Age'].mask(original_data['Age'] > 45 , 2)
    original_data['Age'] = original_data['Age'].mask(original_data['Age'] > 30 , 1)
    original_data['Age'] = original_data['Age'].mask(original_data['Age'] > 5 , 0)
    
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 500 , 5)
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 400 , 4)
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 300 , 3)
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 200 , 2)
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 100 , 1)
    original_data['Cholesterol'] = original_data['Cholesterol'].mask(original_data['Cholesterol'] > 10 , 0)
    
    original_data['MaxHR'] = original_data['MaxHR'].mask(original_data['MaxHR'] > 160 , 3)
    original_data['MaxHR'] = original_data['MaxHR'].mask(original_data['MaxHR'] > 120 , 2)
    original_data['MaxHR'] = original_data['MaxHR'].mask(original_data['MaxHR'] > 80 , 1)
    original_data['MaxHR'] = original_data['MaxHR'].mask(original_data['MaxHR'] > 40 , 0)
    
    original_data['RestingBP'] = original_data['RestingBP'].mask(original_data['RestingBP'] > 170 , 3)
    original_data['RestingBP'] = original_data['RestingBP'].mask(original_data['RestingBP'] > 140 , 2)
    original_data['RestingBP'] = original_data['RestingBP'].mask(original_data['RestingBP'] > 110 , 1)
    original_data['RestingBP'] = original_data['RestingBP'].mask(original_data['RestingBP'] > 80 , 0)
    

    # writing  the dataframe to another csv file
    original_data.to_csv('./static/datasets/heart_quantitative2.csv',
                     index=False)
    reduced_data = pd.read_csv('./static/datasets/heart_quantitative2.csv')
    reduced_data.drop(reduced_data[reduced_data['HeartDisease'] == 0].index, inplace = True)    
    reduced_data.to_csv('./static/datasets/heart_reduced2.csv',
                     index=False)

    #Load new data
    new_data = pd.read_csv('./static/datasets/heart_quantitative.csv')
    new_data.head()

    correlation = new_data.corr()
    plt.figure(figsize=(10,10))
    sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='viridis')

    plt.title('Correlation between different features')

    #Data often contains nulls and we usually need to deal with is in some way, or many of our analyses will fail.
    #Let's see if our data contains nulls by running the 'info()' method on our Dataframe:
    new_data.info()

    X = new_data.iloc[:,1:12]  # all rows, all the features and no labels
    y = new_data.iloc[:, 0]  # all rows, label only

    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    X =scaler.fit_transform(X)
    X

    from sklearn.decomposition import PCA
    pca = PCA()
    pca.fit_transform(X)

    pca.get_covariance()

    explained_variance=pca.explained_variance_ratio_
    explained_variance

    with plt.style.context('dark_background'):
        plt.figure(figsize=(6, 4))

        plt.bar(range(8), explained_variance, alpha=0.5, align='center',
                label='individual explained variance')
        plt.ylabel('Explained variance ratio')
        plt.xlabel('Principal components')
        plt.legend(loc='best')
        plt.tight_layout()

    pca.get_covariance()

    explained_variance=pca.explained_variance_ratio_
    explained_variance

    with plt.style.context('dark_background'):
        plt.figure(figsize=(6, 4))

        plt.bar(range(8), explained_variance, alpha=0.5, align='center',
                label='individual explained variance')
        plt.ylabel('Explained variance ratio')
        plt.xlabel('Principal components')
        plt.legend(loc='best')
        plt.tight_layout()